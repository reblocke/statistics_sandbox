{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow for transcribing audio files with whisper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/reblocke/audio_transcripts/transcription_29_03_25_at_13-33.flac\n",
      "/Users/reblocke/audio_transcripts/transcription_29_03_25_at_13-33.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import subprocess\n",
    "\n",
    "#working_folder = \"\"\n",
    "working_folder = \"/Users/reblocke/audio_transcripts\"\n",
    "os.makedirs(working_folder, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"transcription_%y-%m-%d_at_%H-%M.flac\")\n",
    "audio_output_path = os.path.join(working_folder, timestamp)\n",
    "text_output_path = os.path.splitext(audio_output_path)[0] + \".txt\"\n",
    "\n",
    "print(audio_output_path)\n",
    "print(text_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Command to record the transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, this can be done with the following terminal command:\n",
    "\n",
    "!ffmpeg -f avfoundation -i \":2\" -ac 1 -ar 16000 -b:a 192k output.wav   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.1.1 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with Apple clang version 16.0.0 (clang-1600.0.26.6)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1.1_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.101 / 61. 19.101\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "2025-03-29 13:33:13.714 ffmpeg[82946:8292629] WARNING: Add NSCameraUseContinuityCameraDeviceType to your Info.plist to use AVCaptureDeviceTypeContinuityCamera.\n",
      "2025-03-29 13:33:14.253 ffmpeg[82946:8292629] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n",
      "Input #0, avfoundation, from ':2':\n",
      "  Duration: N/A, start: 359340.314042, bitrate: 1536 kb/s\n",
      "  Stream #0:0: Audio: pcm_f32le, 48000 Hz, mono, flt, 1536 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_f32le (native) -> flac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[flac @ 0x136f95e60] encoding as 24 bits-per-sample, more is considered experimental. Add -strict experimental if you want to encode more than 24 bits-per-sample\n",
      "Output #0, flac, to '/Users/reblocke/audio_transcripts/transcription_29_03_25_at_13-33.flac':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.7.100\n",
      "  Stream #0:0: Audio: flac, 16000 Hz, mono, s32 (24 bit), 192 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.19.101 flac\n",
      "size=    2816KiB time=00:01:51.33 bitrate= 207.2kbits/s speed=   1x     \r"
     ]
    }
   ],
   "source": [
    "# Start ffmpeg and enable writing to its stdin.\n",
    "process = subprocess.Popen(\n",
    "    ['ffmpeg', '-f', 'avfoundation', '-i', ':2', '-ac', '1', '-ar', '16000', '-b:a', '192k', audio_output_path],\n",
    "    stdin=subprocess.PIPE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the below box to stop the recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[q] command received. Exiting.\n",
      "\n",
      "[out#0/flac @ 0x136f2a890] video:0KiB audio:2947KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.274574%\n",
      "size=    2955KiB time=00:01:51.86 bitrate= 216.4kbits/s speed=   1x    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.communicate(input=b'q')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Command to transcribe the audio just recorded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We will provide an answer to both these questions below but from a starting point anathema to the pure epistemically utility theorist, avoiding appeal to intrinsic epistemic goodness entirely, we will assume that all value is ultimately grounded in practical value. From this starting point of expected utility maximization, we can understand accuracy's practical role by repurposing a representation theorem from Sherbysh, 1989. Here's the idea in brief. Suppose you have a credence of 0.3 that it will rain, you may end up having to make a decision at some point on the basis of this credence such as whether to bring an umbrella, whether to drive instead of walk, or whether to accept a monetary bet that pays off just in case it in fact rains. You do not yet need to know for sure which particular decisions you will have to make, but you do know that the less accurate your credence is, the more likely it is that you will make what turns out to be the wrong decision relative to your desires. So you can assign your credence an expected loss, i.e. a negative expected utility, by averaging over the values of the possible good and bad decisions you might have to make based on it. As we will see from Sherbysh's theorem, under some natural assumptions, this method generates exactly the sort of measures of inaccuracy that MSTM utility theorists find acceptable. That is, we expect loss functions of a rational agent uses to assign a practical value to his or her own credence, or to evaluate another agent's credence is simply a proper scoring rule. Moreover, Sherbysh's theorem will allow us to represent an agent with a single measure of inaccuracy that reflects her expectations of the kinds of practical decisions she will have to make. Sherbysh's theorem, under some of the rules, she will have to make.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"turbo\")\n",
    "result = model.transcribe(audio_output_path, fp16=False)\n",
    "print(result[\"text\"])\n",
    "with open(text_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete the output_path file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(audio_output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
